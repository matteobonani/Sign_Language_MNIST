{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we upload the two dataset of the sign mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27455 entries, 0 to 27454\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 164.4 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     13     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('sign_mnist_train.csv')\n",
    "df.info()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 24\n",
      "Class distribution:\n",
      "0     1126\n",
      "1     1010\n",
      "2     1144\n",
      "3     1196\n",
      "4      957\n",
      "5     1204\n",
      "6     1090\n",
      "7     1013\n",
      "8     1162\n",
      "10    1114\n",
      "11    1241\n",
      "12    1055\n",
      "13    1151\n",
      "14    1196\n",
      "15    1088\n",
      "16    1279\n",
      "17    1294\n",
      "18    1199\n",
      "19    1186\n",
      "20    1161\n",
      "21    1082\n",
      "22    1225\n",
      "23    1164\n",
      "24    1118\n",
      "Name: label, dtype: int64\n",
      "Skew:-0.43129847690785494 and 0.0732183141355446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label      -0.095249\n",
       "pixel1     -0.558068\n",
       "pixel2     -0.577706\n",
       "pixel3     -0.645864\n",
       "pixel4     -0.772380\n",
       "              ...   \n",
       "pixel780   -0.916529\n",
       "pixel781   -0.954015\n",
       "pixel782   -0.947602\n",
       "pixel783   -0.952318\n",
       "pixel784   -0.930335\n",
       "Length: 785, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of images per class\n",
    "class_counts = df['label'].value_counts().sort_index()\n",
    "\n",
    "\n",
    "# Compute the skew\n",
    "\n",
    "skew2 = 3*(class_counts.mean() - class_counts.median()) / class_counts.std()\n",
    "skew = class_counts.std() / class_counts.mean()\n",
    "print(f\"Number of classes: {len(class_counts)}\")\n",
    "print(f\"Class distribution:\\n{class_counts}\")\n",
    "print(f\"Skew:{skew2} and {skew}\")\n",
    "df.skew()\n",
    "\n",
    "# 3 * (mean–median) / standard deviation = skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_image(dataset, index):\n",
    "    image = dataset.iloc[index, 1:].values.reshape(28, 28)\n",
    "    label = dataset.iloc[index, 0]\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Usage example:\n",
    "show_image(df, 6)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best ML model to classify these image should be the random forest deicsion tree or the KNN\n",
    "\n",
    "K Nearest Neighbors (KNN): KNN is a simple and intuitive classification algorithm that assigns labels to data points based on the labels of their nearest neighbors in the feature space. KNN can be a reasonable choice for this task, as it can capture local patterns in the image data. However, KNN might not scale well to large datasets and can be sensitive to irrelevant features. Given the size of the Sign Language MNIST dataset, KNN can be a viable option to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
